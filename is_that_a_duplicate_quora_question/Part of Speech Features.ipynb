{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import operator\n",
    "import spacy\n",
    "import en_core_web_md\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "FILE_NAME = 'spacy_part_of_speech_features.csv'\n",
    "\n",
    "df_train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "df_test  = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "df_train = df_train.head(10)\n",
    "df_test  = df_test.head(10)\n",
    "    \n",
    "POS_TYPES = [\n",
    "    'PUNCT', 'SYM', 'ADJ', 'VERB',\n",
    "    'CONJ', 'NUM', 'DET', 'ADV',\n",
    "    'ADP', 'NOUN', 'PROPN', 'PART',\n",
    "    'PRON', 'INTJ',\n",
    "]\n",
    "\n",
    "POS_FEATURES = ['Q1_' + i for i in POS_TYPES] +\\\n",
    "               ['Q2_' + i for i in POS_TYPES] +\\\n",
    "               ['SHARED_' + i for i in POS_TYPES] +\\\n",
    "               ['JACCARD_' + i for i in POS_TYPES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __jaccard_distance(A, B, I):\n",
    "    if A == B == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 1.0 - ( I / ((A + B) - I))\n",
    "\n",
    "def get_pos_counts(row):\n",
    "\n",
    "    doc1 = [] if type(row['question1']) != str else nlp(row['question1'])\n",
    "    doc2 = [] if type(row['question2']) != str else nlp(row['question2'])\n",
    "    pos_data = {pos: [set([]), set([])] for pos in POS_TYPES}\n",
    "    pos_features = {}\n",
    "\n",
    "    if doc1 == doc2 == []:\n",
    "        return '0:0:0:2'\n",
    "\n",
    "    for t in doc1:\n",
    "        if t.pos_ in pos_data:\n",
    "            pos_data[t.pos_][0].add(t.text.lower())\n",
    "\n",
    "    for t in doc2:\n",
    "        if t.pos_ in pos_data:\n",
    "            pos_data[t.pos_][1].add(t.text.lower())\n",
    "\n",
    "    for pos in POS_TYPES:\n",
    "        q1 = len(pos_data[pos][0])\n",
    "        q2 = len(pos_data[pos][1])\n",
    "        shared = len(pos_data[pos][0].intersection(pos_data[pos][1]))\n",
    "        pos_features['Q1_' + pos] = q1\n",
    "        pos_features['Q2_' + pos] = q2\n",
    "        pos_features['SHARED_' + pos] = shared\n",
    "        pos_features['JACCARD_' + pos] = __jaccard_distance(q1, q2, shared)\n",
    "\n",
    "    return ('{}:{}:{}:{}:'*len(POS_TYPES)).format(*[pos_features[i] for i in POS_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    nlp = en_core_web_md.load()\n",
    "\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    df['word_shares'] = df.apply(get_pos_counts, axis=1, raw=True)\n",
    "\n",
    "    x = pd.DataFrame()\n",
    "\n",
    "    for index, pos_features in enumerate(POS_FEATURES):\n",
    "        x[pos_features] = df['word_shares'].apply(lambda x: float(x.split(':')[ index ]))\n",
    "    \n",
    "    if len(df.index) < 1000:\n",
    "        DATA_PATH += 'test/'\n",
    "\n",
    "    x_train = x[:df_train.shape[0]]\n",
    "    x_test  = x[df_train.shape[0]:]\n",
    "    x_train.to_csv(DATA_PATH + 'train_' + FILE_NAME)\n",
    "    x_test.to_csv(DATA_PATH + 'test_' + FILE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
